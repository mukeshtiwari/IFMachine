%%
%% This is file `sample-sigplan.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigplan')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigplan.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigplan,screen]{acmart}
\usepackage{algorithm}
\usepackage{listings}
\usepackage{algpseudocode}
%% NOTE that a single column version is required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen,review]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.

\setcopyright{acmcopyright}
\copyrightyear{}
\acmYear{}
\acmDOI{}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[]{}{}{}
\acmBooktitle{Program Analysis and Verification on Trusted
Platforms (PAVeTrust) Workshop}
\acmPrice{}
\acmISBN{}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Towards Leakage-Resistant Machine Learning in Trusted Execution Environments}

%%
%% The "author" command and its associated commands are used to defineout

%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.






%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%%\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
    

  Emergence of Trusted Execution Environments (TEEs), e.g., SGX and ARM TrustZone 
  in cloud services has led to the processing of 
  many security critical data, e.g., medical records, financial records, etc., 
  in the cloud. However, TEEs are known to be vulnerable to side
  channel attacks, in which the untrusted operating system infers 
  secret data by observing the behaviour of an enclave during its execution. 
  One possible remedy for this problem is to write information flow secure,
  i.e., no secret-dependent (constant-time) branch code.
  
  In this ongoing work, we develop a formally verified information flow secure (constant-time)
  gradient descent algorithm,  
  except we instantiate the gradient calculation with (axiomatic differential 
  private) linear regression. 
  Moreover, we demonstrate the usability of our application by running it on 
  synthetically generated data and the results are promising.
  
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{comment}
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}
\end{comment}
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{formal verification, information flow security, machine learning}




%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}

 In recent years, many organisations are moving towards machine learning to get 
 the maximum utility from their data, generated by the various processes. 
 However, machine learning algorithms are computationally expensive, 
 many organisations are outsourcing the training to cloud (service providers). 
 In most cases, training machine learning models in cloud is not 
 an issue but in some situation when data contains sensitive information, e.g., health care, 
 political view, sexual orientation, etc., cloud providers can't be trusted with 
 processing sensitive data. Trustworthy Execution Environment, such as Intel 
 SGX \cite{10.1145/2487726.2488368}  and ARM TrustZone \cite{alves2004trustzone}, 
 has emerged as a promising solution, to execute a program on sensitive data in 
 a untrustworthy cloud machine. 
 
 
 Trusted Execution Environment (SGX) guarantees isolated environment, also known as enclave, 
 to protect the code and data from the outside software environment, including 
 the operating system. Therefore, it has found numerous usage in security 
 critical application,  including  machine learning on 
 sensitive data \cite{TB19a, kunkel2019tensorscone, hunt2018chiron, hynes2018efficient, 
 mo2021ppfl}. Although SGX thread model provides security guarantee from 
 many attacks (cite the paper of security guarantee); it does not 
 promise any security from information flow attacks \cite{xu2015controlled, 
 10.5555/3154768.3154779, moghimi2017cachezoom, gotzfried2017cache, van2017telling, 
 lee2017inferring, moghimi2020copycat, puddu2020frontal, van2018foreshadow}.
 However, to mitigate these side channels, Intel has suggested three 
 "constant time" principals\footnote{\url{https://software.intel.com/content/www/us/en/develop/articles/software-security-guidance/secure-coding/mitigate-timing-side-channel-crypto-implementation.html}}:
 \begin{itemize}
     \item Ensure runtime is independent of secret values.
    \item Ensure code access patterns are independent of secret values.
    \item Ensure data access patterns are independent of secret values.
 \end{itemize}

 \noindent
 In addition, Intel has stated that:
 \begin{quote}
    These principles are conceptually simple, but sometimes can be difficult to 
 implement in practice, depending on the complexity of your algorithms. Luckily, 
 most developers wonâ€™t need to work on the most complex situations.    
 \end{quote}
   
 Indeed, these principals are difficult to implement in complex 
 algorithm because \cite{kunkel2019tensorscone, hunt2018chiron, TB19a} are 
 susceptible to these attacks.
 There are some proposals \cite{10.1145/2897845.2897885, shih2017t, chen2017detecting} 
 to mitigate the side channel attacks; however, in presence of Frontal \cite{puddu2020frontal} attack 
 %--which 
 %exploits timing differences of various CPU instruction and 
 %can extract a secret from an SGX enclave even if that secret was used
 %as a branching condition for two instruction-wise identical branches;
 %therefore, it forbids the secret-dependent branches-- and 
 and CopyCat \cite{moghimi2020copycat}
 attack, 
 %--which can recover the secret by counting the instructions in two blocks of 
 %a secret-dependent branch--; 
 a true solution, we believe,
 is formally ensuring that the program, executing in SGX, is constant time, independent 
 of any secret branching or memory access. 
 

 In our ongoing work, we report first, to the best of our knowledge, formally verified 
 constant time 
 gradient descent algorithm \cite{abadi2016deep}, where the gradient computation is 
 instantiated with differential private linear regression \cite{alabi2020differentially}.
 We have used the tool SecCSL \cite{10.1007/978-3-030-25543-5_13} 
 to develop and prove that our implementation is memory safe and 
 ensures all the above three principles, suggested by Intel. Our experiments 
 shows promising results  on synthetic data, generated by some predefined equation of a line. 
 In future work, we intend to extend our formally verified C code to run 
 inside SGX, running experiments on real world data, and making it 
 more amenable to federated learning. 
 



\begin{comment}

\section{Background}
\subsection{Information Flow Security (Secure C)}


\subsection{Machine Learning}

\subsection{Trusted Execution Environment}

\subsection{Differential Privacy}


\section{Problem Formulation}
 There are n clients that don't want to share their data with 
 a server and therefore the server sends the model parameter to 

\end{comment}
 
 
\section{Technical Details}
At a very high level, our algorithm  (Algorithm \ref{constant-time}) is very 
similar to \cite{ abadi2016deep}, 
except we instantiate the gradient calculation by linear regression because 
our goal, very similar to \cite{alabi2020differentially}, is to process 
relatively small amount of sensitive data \cite{NBERw25626, NBERw19843, 622437}, resulting from 
social science experiments. However, on the contrary to \cite{alabi2020differentially}, 
we are mostly interested in running the (data) analysis securely in TEEs without any 
side channel information leak. Therefore, we take an axiomatic approach for differential 
privacy, i.e., we assume that the Laplacian noise generator unverified (library) function is correct, 
right amount of noise is added during the analysis, etc. However, to compensate
these assumption, we generate certificate that records various crucial information,
during the execution of program.  In case of discrepancy, an auditor can inspect 
the certificate and ascertain the validity of execution. 
%%Informal: how do we know 
%that it generates correct scrutiny sheet? Explain it and the traces (read OOPSLA 
%paper). 


 Now, zooming to the details, (Algorithm \ref{constant-time}) takes input as  
 number of data points ($n$), number of iterations ($T$), clipping range($t$), 
 initial guess of two parameters ($\theta_{1}^{0}$, $\theta_{2}^{0}$), learning 
 rate ($\gamma$), and privacy parameter ($\epsilon$) and in each iteration, it performs: 
 \begin{itemize}
     \item for every $x_{i}$, in the data:
     \begin{itemize}
         \item it computes/predicts $\tilde{y}_{i}$, 
       using the (so far) computed $\theta_{1}^{t}$  and  $\theta_{2}^{t}$ (line 5).
     \item then it computes the gradient $\Delta_{i, t}$, using $x_{i}, y_{i}$, and $\tilde{y}_{i}$
       (line 6).
     \item finally, the gradient $\Delta_{i, t}$ is clipped, i.e., if the value $\Delta_{i, t}$ is 
     below $-t$ then it is changed to $-t$, if it is above $t$ then it is changed to $t$, otherwise 
     it remains unchanged (line 7).
     \end{itemize}
    \item we sum all the (clipped) gradients and add Laplacian noise (line 9)
    \item and finally, compute (improve) new values $\theta_{1}^{t+1}$, $\theta_{2}^{t+1}$ (line 10 and
     it is known as taking a descent).
 \end{itemize}


\begin{algorithm}
  \caption{Constant Time Gradient Descent}\label{constant-time}
  \begin{algorithmic}[1]
    \Procedure{Constant-DPGD}{$n, T, t, \theta_{1}^{0}, \theta_{2}^{0}, 
    \gamma, \epsilon$} \Comment{number of data points, 
    number of iterations, clipping range, initial (guess) slope, initial (guess) intercept,
    learning rate, privacy parameter}
    \State Data: $\{(x_{i}, y_{i})\}_{i=1}^n$
    \For{\texttt{t := 1 to T}}
        \For{\texttt{i := 1 to n}}
            \State $\tilde{y}_{i} =  \theta_{1}^{t} * x_{i} + \theta_{2}^{t}$
            \State $\Delta_{i, t} = \begin{pmatrix} 
                                    2(\tilde{y}_{i} - y_{i}) x_{i} \\
                                    2(\tilde{y}_{i} - y_{i})\\
                                    \end{pmatrix}$
            \State $\Delta_{i, t}^{c} = \{\Delta_{i, t}\}_{-t}^{t}$ 
            
        \EndFor
        
        \State $\Delta_{t}  = \frac{1}{n}\sum_{i=1}^{n} \Delta_{i, t}^{c} + Lap(0, 4 t / \epsilon)$
        \State $[\theta_{1}^{t+1}, \theta_{2}^{t+1}] = [\theta_{1}^{t}, \theta_{2}^{t}] - \gamma * \Delta_{t}$ 
    
    \EndFor
    
    \State return $[\theta_{1}^{T+1}, \theta_{2}^{T+1}]$
    
  
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

 \noindent
 We use \textit{Secure C} \cite{10.1007/978-3-030-25543-5_13} to formally verify 
 that our implementation is constant-time. During our modelling, we assume that the training data is 
 secret and therefore we assign it a \textit{high} value. What it means is that we can 
 no longer branch or loop on the training data or any other derived value from it, to
 avoid the secret-dependent branching. However, there are some steps, e.g., gradient clipping
 (line 7) which can be naturally expressed using \textit{if else } construct, but we cannot
 because of no branching on secret rule. Therefore, we write it without \textit{if else } construct
 and prove that it is correct (see the snippet, Gradient clipping snippet \ref{grad-clip}, from the gradient clipping function).
\begin{figure}[h!]
\begin{verbatim}
    
    int kl = l + h;
    _(assert kl == 0 || kl == 1 || kl == -1)
    int kr = abs(kl);
    _(assert kr == abs_to_int(kl))
    double retm = tau * kl + (1 - kr) * m;
  
    _(apply bounded_lemma(l, h, kl, kr, m, tau, retm);)
    // Proof that retm is within [-tau, tau]
    _(assert -tau <= retm && retm <= tau)
    gs->m = retm;
    
\end{verbatim}\caption{Gradient clipping snippet}\label{grad-clip}
\end{figure}

\section{Experiments}
Our experiments, so far, are very promising on synthetic data. For example, we generate 
synthetic data according to the equation $y = \theta_{1} * x + \theta_{2}$, 
where $\theta_{1}$ = 1.0 and $\theta_{2}$ = 0.0 (and many other values), 
run our implementation first without adding any noise (no differential privacy)
and second with noise. In the first case, without noise, our implementation 
produces/predicts the value of $\theta_{1}$ = 0.990 and $\theta_{2}$ = 0.0010, very 
close to the actual. In the second case, with noise, we start with $\epsilon$ = 0.01
and get $\theta_{1}$ = 0.97924 and $\theta_{2}$ =  0.010800 while with 
$\epsilon$ = 0.1 we get $\theta_{1}$ = 0.525030 and $\theta_{2}$ = 0.312111.
We stress that these are preliminary results and it requires more experimentation.



\begin{comment}


\section{Related Work}
while \cite{hynes2018efficient} addresses 
 --by adding more complexity and thus hampering the performance 
 (cite some paper on performance penalty)--
 the side channel by data-oblivious \cite{ohrimenko2016oblivious} algorithm. 

\section{Future Work}

\begin{itemize}
    \item Writing bindings for Intel SGX
    \item Turning it into Federated Learning
    \item Running More experiments (the defacto one from machine learning community)
    \item 
\end{itemize}
\end{comment}

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
%%\begin{acks}
%%To Robert, for the bagels and explaining CMYK and color spaces.
%%\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}


\end{document}
\endinput
%%
%% End of file `sample-sigplan.tex'.
